"""
Financial Analytics Suite - Machine Learning Lab Page
Feature engineering, model training, evaluation, and experiment tracking
ALL MODELS REQUIRE USER ACTION TO TRAIN - No auto-generation
WITH DOWNLOAD OPTIONS for graphs and tables
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from typing import Dict, List
import io

# Import data manager
from pages_new.data_manager import (
    get_working_data, get_working_data_info, has_data,
    get_available_tickers
)

# Import theme utilities
from pages_new.theme_utils import get_theme_colors

# Import model results manager
from pages_new.model_results_manager import (
    save_model_result, get_model_result, has_model_been_run,
    get_category_results, get_run_history
)


def dataframe_to_excel(df):
    """Convert dataframe to Excel bytes"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Data')
    return output.getvalue()


def render_download_buttons(fig=None, df=None, name="download"):
    """Render download buttons for figure and/or dataframe"""
    cols = st.columns(4)
    
    if fig is not None:
        with cols[0]:
            try:
                html_str = fig.to_html(include_plotlyjs='cdn')
                st.download_button(
                    "üì• HTML",
                    data=html_str,
                    file_name=f"{name}.html",
                    mime="text/html",
                    key=f"dl_html_{name}_{hash(str(fig))%10000}",
                    use_container_width=True
                )
            except:
                pass
    
    if df is not None:
        with cols[1]:
            csv_data = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• CSV",
                data=csv_data,
                file_name=f"{name}.csv",
                mime="text/csv",
                key=f"dl_csv_{name}_{hash(str(df))%10000}",
                use_container_width=True
            )
        
        with cols[2]:
            try:
                excel_data = dataframe_to_excel(df)
                st.download_button(
                    "üì• Excel",
                    data=excel_data,
                    file_name=f"{name}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=f"dl_xlsx_{name}_{hash(str(df))%10000}",
                    use_container_width=True
                )
            except:
                pass


# ML Models
ML_MODELS = {
    'regression': [
        {'name': 'Linear Regression', 'icon': 'üìè', 'compute': 'Low', 'interpretable': True},
        {'name': 'Ridge Regression', 'icon': 'üèîÔ∏è', 'compute': 'Low', 'interpretable': True},
        {'name': 'Lasso Regression', 'icon': 'üîó', 'compute': 'Low', 'interpretable': True},
        {'name': 'ElasticNet', 'icon': 'üï∏Ô∏è', 'compute': 'Low', 'interpretable': True},
        {'name': 'Random Forest', 'icon': 'üå≤', 'compute': 'Medium', 'interpretable': False},
        {'name': 'Gradient Boosting', 'icon': 'üöÄ', 'compute': 'Medium', 'interpretable': False},
        {'name': 'XGBoost', 'icon': '‚ö°', 'compute': 'Medium', 'interpretable': False},
        {'name': 'SVR', 'icon': 'üéØ', 'compute': 'High', 'interpretable': False},
    ],
    'classification': [
        {'name': 'Logistic Regression', 'icon': 'üìä', 'compute': 'Low', 'interpretable': True},
        {'name': 'Random Forest', 'icon': 'üå≤', 'compute': 'Medium', 'interpretable': False},
        {'name': 'Gradient Boosting', 'icon': 'üöÄ', 'compute': 'Medium', 'interpretable': False},
        {'name': 'XGBoost', 'icon': '‚ö°', 'compute': 'Medium', 'interpretable': False},
        {'name': 'SVM', 'icon': 'üéØ', 'compute': 'High', 'interpretable': False},
        {'name': 'Neural Network', 'icon': 'üß†', 'compute': 'High', 'interpretable': False},
    ]
}

# NOTE: We no longer use sample experiment runs - only show actually trained models


def generate_feature_importance() -> pd.DataFrame:
    """Generate sample feature importance data"""
    features = ['momentum_20d', 'volatility_30d', 'rsi_14', 'macd_signal', 'volume_ratio', 
                'price_sma_ratio', 'sector_return', 'market_cap', 'pe_ratio', 'dividend_yield']
    importance = np.array([0.18, 0.15, 0.12, 0.11, 0.10, 0.09, 0.08, 0.07, 0.05, 0.05])
    
    return pd.DataFrame({'feature': features, 'importance': importance})


def render_feature_importance(c: Dict) -> None:
    """Render feature importance chart"""
    df = generate_feature_importance()
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=df['importance'],
        y=df['feature'],
        orientation='h',
        marker=dict(
            color=df['importance'],
            colorscale=[[0, c['accent']], [1, c['primary']]],
        ),
        text=[f"{v:.1%}" for v in df['importance']],
        textposition='outside',
        textfont=dict(size=10, color=c['text_secondary']),
        hovertemplate='%{y}<br>Importance: %{x:.2%}<extra></extra>'
    ))
    
    fig.update_layout(
        margin=dict(t=20, l=10, r=60, b=10),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        font=dict(family='Inter', color=c['text']),
        xaxis=dict(
            showgrid=True,
            gridcolor=c['border'],
            tickformat='.0%',
            tickfont=dict(size=10, color=c['text_muted'])
        ),
        yaxis=dict(
            tickfont=dict(size=11, color=c['text']),
            categoryorder='total ascending'
        ),
        height=350
    )
    
    st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})


def render_confusion_matrix(c: Dict) -> None:
    """Render confusion matrix for classification"""
    cm = np.array([[145, 12], [8, 135]])
    labels = ['Negative', 'Positive']
    
    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=labels,
        y=labels,
        colorscale=[[0, c['bg_card']], [1, c['primary']]],
        text=cm,
        texttemplate='%{text}',
        textfont=dict(size=16, color='white'),
        hovertemplate='Actual: %{y}<br>Predicted: %{x}<br>Count: %{z}<extra></extra>',
        showscale=False
    ))
    
    fig.update_layout(
        margin=dict(t=30, l=10, r=10, b=10),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        font=dict(family='Inter', color=c['text']),
        xaxis=dict(title='Predicted', tickfont=dict(size=11)),
        yaxis=dict(title='Actual', tickfont=dict(size=11)),
        height=250
    )
    
    st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})


def render_roc_curve(c: Dict) -> None:
    """Render ROC curve"""
    np.random.seed(42)
    
    # Generate ROC curve data
    fpr = np.linspace(0, 1, 100)
    tpr = 1 - (1 - fpr) ** 2.5  # Simulate good model
    
    fig = go.Figure()
    
    # Convert hex to rgba for Plotly compatibility
    primary_hex = c['primary'].lstrip('#')
    primary_rgb = tuple(int(primary_hex[i:i+2], 16) for i in (0, 2, 4))
    fill_rgba = f'rgba({primary_rgb[0]}, {primary_rgb[1]}, {primary_rgb[2]}, 0.12)'
    
    # ROC curve
    fig.add_trace(go.Scatter(
        x=fpr,
        y=tpr,
        mode='lines',
        line=dict(color=c['primary'], width=2),
        fill='tozeroy',
        fillcolor=fill_rgba,
        name=f'Model (AUC = 0.94)',
        hovertemplate='FPR: %{x:.2f}<br>TPR: %{y:.2f}<extra></extra>'
    ))
    
    # Diagonal
    fig.add_trace(go.Scatter(
        x=[0, 1],
        y=[0, 1],
        mode='lines',
        line=dict(color=c['text_muted'], width=1, dash='dash'),
        name='Random',
        hoverinfo='skip'
    ))
    
    fig.update_layout(
        margin=dict(t=20, l=10, r=10, b=10),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        font=dict(family='Inter', color=c['text']),
        xaxis=dict(title='False Positive Rate', showgrid=True, gridcolor=c['border']),
        yaxis=dict(title='True Positive Rate', showgrid=True, gridcolor=c['border']),
        legend=dict(
            x=0.6, y=0.1,
            font=dict(size=10, color=c['text_secondary']),
            bgcolor='rgba(0,0,0,0)'
        ),
        height=280
    )
    
    st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})


def render_experiment_row(run: Dict, c: Dict) -> None:
    """Render an experiment run row"""
    tags_html = ""
    for tag in run['tags']:
        color = c['success'] if tag == 'best' else c['primary']
        # Convert hex to rgba
        color_hex = color.lstrip('#')
        color_rgb = tuple(int(color_hex[i:i+2], 16) for i in (0, 2, 4))
        color_bg = f'rgba({color_rgb[0]}, {color_rgb[1]}, {color_rgb[2]}, 0.12)'
        tags_html += f'<span style="background: {color_bg}; color: {color}; padding: 2px 6px; border-radius: 4px; font-size: 9px; font-weight: 600; margin-left: 6px;">{tag.upper()}</span>'
    
    row_html = f'<div style="display: grid; grid-template-columns: 100px 1.5fr 80px 2fr 60px 150px; align-items: center; padding: 12px 16px; background: {c["bg_card"]}; border: 1px solid {c["border"]}; border-radius: 10px; margin-bottom: 8px; font-size: 12px;"><div style="color: {c["text_muted"]}; font-family: monospace;">{run["id"]}</div><div style="color: {c["text"]}; font-weight: 600;">{run["model"]}{tags_html}</div><div style="color: {c["success"]}; font-weight: 700;">{run["metric"]:.3f}</div><div style="color: {c["text_muted"]}; font-size: 11px;">{run["params"]}</div><div style="color: {c["text_muted"]};">{run["time"]}</div><div style="color: {c["text_muted"]}; font-size: 11px;">{run["date"]}</div></div>'
    st.markdown(row_html, unsafe_allow_html=True)



def render():
    """Render the ML Lab page"""
    c = get_theme_colors()
    
    # Header
    st.title("üß™ Machine Learning Lab")
    st.markdown(f"<p style='color: {c['text_secondary']}; font-size: 14px; margin-top: -10px;'>Train, evaluate, and compare machine learning models</p>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Check for data - REQUIRE user data
    if not has_data():
        st.markdown(f"""
        <div style="text-align: center; padding: 60px 20px;">
            <div style="font-size: 64px; margin-bottom: 20px;">üß™</div>
            <h2 style="color: {c['text']}; margin-bottom: 12px;">No Data Loaded</h2>
            <p style="color: {c['text_secondary']}; font-size: 16px; max-width: 500px; margin: 0 auto;">
                Upload your data in the Data Sources page to train machine learning models on your own data.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("üì• Go to Data Sources", type="primary", use_container_width=True, key="goto_data_ml"):
                st.session_state.current_page = 'data_sources'
                st.rerun()
        
        st.markdown("---")
        st.info("üí° **Tip:** Upload a CSV or Excel file with financial data to train predictive models.")
        return
    
    # Show data status
    data_info = get_working_data_info()
    st.markdown(f'<div style="background: rgba(16, 185, 129, 0.1); border: 1px solid rgba(16, 185, 129, 0.3); border-radius: 12px; padding: 12px 20px; margin-bottom: 20px;"><span style="font-size: 16px;">‚úÖ</span> <span style="color: {c["text"]}; font-weight: 600;">Using Your Data:</span> <span style="color: {c["text_secondary"]};">{data_info["name"]} ({data_info["rows"]:,} rows)</span></div>', unsafe_allow_html=True)
    
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs(["üéØ Setup", "üèãÔ∏è Training", "üìä Evaluation", "üìã Experiments"])
    
    with tab1:
        # Setup Tab
        setup_cols = st.columns([1, 2])
        
        with setup_cols[0]:
            st.markdown("#### Task Configuration")
            
            task_type = st.radio(
                "Task Type",
                ["Regression", "Classification"],
                help="Select the type of ML task"
            )
            
            st.markdown("---")
            
            # Dataset - use real data (data is guaranteed available at this point)
            data_info = get_working_data_info()
            st.success(f"üìä Using: **{data_info['name']}**")
            st.caption(f"{data_info['rows']:,} rows √ó {data_info['columns']} columns")
            
            df = get_working_data()
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist() if df is not None else []
            target_options = ['returns', 'daily_return'] + [col for col in numeric_cols if col not in ['date', 'Date']][:5]
            st.selectbox("Target Variable", target_options, key="target_var")
            
            st.markdown("---")
            
            # Split
            st.markdown("#### Data Split")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.number_input("Train %", 50, 90, 70, step=5)
            with col2:
                st.number_input("Valid %", 5, 30, 15, step=5)
            with col3:
                st.number_input("Test %", 5, 30, 15, step=5)
            
            st.checkbox("Use Time-based Split", value=True)
            st.checkbox("Enable Cross-Validation", value=False)
        
        with setup_cols[1]:
            st.markdown("#### Feature Selection")
            
            # Feature groups
            with st.expander("üìä Price Features", expanded=True):
                feature_cols = st.columns(3)
                with feature_cols[0]:
                    st.checkbox("Returns (1d)", value=True)
                    st.checkbox("Returns (5d)", value=True)
                    st.checkbox("Returns (20d)", value=True)
                with feature_cols[1]:
                    st.checkbox("SMA Ratio", value=True)
                    st.checkbox("EMA Ratio", value=False)
                    st.checkbox("Bollinger %B", value=False)
                with feature_cols[2]:
                    st.checkbox("RSI", value=True)
                    st.checkbox("MACD", value=True)
                    st.checkbox("ADX", value=False)
            
            with st.expander("üìà Volatility Features", expanded=False):
                st.checkbox("Rolling Volatility (20d)", value=True)
                st.checkbox("Rolling Volatility (60d)", value=False)
                st.checkbox("GARCH Volatility", value=False)
                st.checkbox("ATR", value=True)
            
            with st.expander("üì¶ Volume Features", expanded=False):
                st.checkbox("Volume Ratio", value=True)
                st.checkbox("OBV", value=False)
                st.checkbox("VWAP Ratio", value=False)
            
            st.markdown("---")
            
            st.markdown("#### Model Selection")
            
            models = ML_MODELS[task_type.lower()]
            model_options = [m['name'] for m in models]
            
            
            selected_models = st.multiselect(
                "Select Models to Train",
                model_options,
                default=model_options[:3]
            )
            
            st.markdown("---")
            
            if st.button("‚ú® Apply & Generate Features", type="primary", use_container_width=True):
                with st.spinner("Generating features..."):
                    try:
                        # process working data
                        df = get_working_data().copy()
                        
                        # Sort by date if possible
                        date_col = None
                        for col in ['date', 'Date', 'DATE', 'datetime']:
                            if col in df.columns:
                                date_col = col
                                break
                        
                        if date_col:
                            try:
                                df[date_col] = pd.to_datetime(df[date_col], utc=True).dt.tz_localize(None)
                            except:
                                try:
                                    df[date_col] = pd.to_datetime(df[date_col])
                                    if df[date_col].dt.tz is not None:
                                        df[date_col] = df[date_col].dt.tz_localize(None)
                                except:
                                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                            df = df.sort_values(date_col)
                        
                        # Find price column
                        price_col = None
                        for col in ['close', 'Close', 'price', 'adj_close']:
                            if col in df.columns:
                                price_col = col
                                break
                        
                        if not price_col:
                            # Fallback to numeric
                            numeric = df.select_dtypes(include=[np.number]).columns
                            if len(numeric) > 0:
                                price_col = numeric[0]
                        
                        if price_col:
                            # 1. Price Features
                            # Returns
                            df['Returns_1D'] = df[price_col].pct_change()
                            df['Returns_5D'] = df[price_col].pct_change(5)
                            df['Returns_20D'] = df[price_col].pct_change(20)
                            
                            # Log Returns
                            df['Log_Returns'] = np.log(df[price_col] / df[price_col].shift(1))
                            
                            # SMA Ratio
                            df['SMA_20'] = df[price_col].rolling(20).mean()
                            df['SMA_Ratio'] = df[price_col] / df['SMA_20']
                            
                            # RSI
                            delta = df[price_col].diff()
                            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                            rs = gain / loss
                            df['RSI'] = 100 - (100 / (1 + rs))
                            
                            # MACD
                            exp1 = df[price_col].ewm(span=12, adjust=False).mean()
                            exp2 = df[price_col].ewm(span=26, adjust=False).mean()
                            df['MACD'] = exp1 - exp2
                            df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
                            
                            # Volatility (Rolling Std Dev)
                            df['Volatility_20D'] = df[price_col].rolling(20).std()
                            
                            # Update session state with new data
                            st.session_state.uploaded_data = df
                            
                            # Also update the data_X keys if they exist
                            for key in list(st.session_state.keys()):
                                if key.startswith("data_upload-"):
                                    st.session_state[key] = df
                            
                            st.success(f"‚úÖ Generated {len(df.columns) - len(get_working_data().columns)} new features! Go to 'Training' tab.")
                            
                        else:
                            st.error("Could not find a price column to generate features.")
                            
                    except Exception as e:
                        st.error(f"Error generating features: {str(e)}")
    
    with tab2:
        # Training Tab - Individual Model Training
        st.markdown("### üèãÔ∏è Train Individual Models")
        st.caption("Click on any model to train it individually and see its results")
        
        # Get user's data
        df = get_working_data()
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) < 2:
            st.warning("Need at least 2 numeric columns for ML training")
            return
        
        # Target and feature selection
        col_setup1, col_setup2 = st.columns(2)
        with col_setup1:
            target_col = st.selectbox("üéØ Target Variable", numeric_cols, key="ml_target")
        with col_setup2:
            feature_cols = st.multiselect("üìä Feature Columns", 
                                         [c for c in numeric_cols if c != target_col],
                                         default=[c for c in numeric_cols if c != target_col][:5],
                                         key="ml_features")
        
        if not feature_cols:
            st.warning("Select at least one feature column")
            return
        
        st.markdown("---")
        
        # All available models for individual training
        all_models = [
            {'name': 'Linear Regression', 'icon': 'üìè', 'type': 'linear'},
            {'name': 'Ridge Regression', 'icon': 'üèîÔ∏è', 'type': 'ridge'},
            {'name': 'Lasso Regression', 'icon': 'üîó', 'type': 'lasso'},
            {'name': 'Random Forest', 'icon': 'üå≤', 'type': 'rf'},
            {'name': 'Gradient Boosting', 'icon': 'üöÄ', 'type': 'gb'},
            {'name': 'XGBoost', 'icon': '‚ö°', 'type': 'xgb'},
        ]
        
        # Create model cards in a grid
        st.markdown("#### Select a Model to Train")
        
        model_cols = st.columns(3)
        
        for idx, model_info in enumerate(all_models):
            col_idx = idx % 3
            model_name = model_info['name']
            model_icon = model_info['icon']
            model_key = f"train_{model_info['type']}"
            
            # Check if model was already trained
            already_trained = has_model_been_run('ml_models', model_name)
            
            with model_cols[col_idx]:
                st.markdown(f"""
                <div style="
                    background: {c['bg_card']};
                    border: 1px solid {c['border']};
                    border-radius: 12px;
                    padding: 16px;
                    margin-bottom: 16px;
                    text-align: center;
                ">
                    <div style="font-size: 32px; margin-bottom: 8px;">{model_icon}</div>
                    <div style="font-weight: 600; color: {c['text']}; margin-bottom: 8px;">{model_name}</div>
                    <div style="font-size: 11px; color: {c['text_muted']};">
                        {'‚úÖ Trained' if already_trained else '‚è≥ Not trained'}
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                if st.button(f"üöÄ Run {model_name}", key=model_key, use_container_width=True):
                    with st.spinner(f"Training {model_name}..."):
                        import time
                        time.sleep(0.5)
                        
                        # Prepare data - Drop NaNs from BOTH X and y simultaneously
                        data_for_model = df[feature_cols + [target_col]].dropna()
                        
                        if len(data_for_model) < 10:
                            st.error(f"‚ùå Not enough data after removing NaNs. Need at least 10 rows, got {len(data_for_model)}.")
                            st.stop()
                            
                        X = data_for_model[feature_cols]
                        y = data_for_model[target_col]
                        
                        # Simple train-test split
                        split_idx = int(len(X) * 0.8)
                        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
                        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
                        
                        # Train model based on type
                        from sklearn.linear_model import LinearRegression, Ridge, Lasso
                        from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
                        
                        if model_info['type'] == 'linear':
                            model = LinearRegression()
                        elif model_info['type'] == 'ridge':
                            model = Ridge(alpha=1.0)
                        elif model_info['type'] == 'lasso':
                            model = Lasso(alpha=0.1)
                        elif model_info['type'] == 'rf':
                            model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
                        elif model_info['type'] == 'gb':
                            model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)
                        elif model_info['type'] == 'xgb':
                            try:
                                from xgboost import XGBRegressor
                                model = XGBRegressor(n_estimators=100, max_depth=6, random_state=42)
                            except ImportError:
                                model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)
                        
                        # Fit model
                        model.fit(X_train, y_train)
                        y_pred = model.predict(X_test)
                        
                        # Calculate metrics
                        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
                        r2 = r2_score(y_test, y_pred)
                        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                        mae = mean_absolute_error(y_test, y_pred)
                        
                        # Feature importance
                        if hasattr(model, 'feature_importances_'):
                            importance = model.feature_importances_
                        elif hasattr(model, 'coef_'):
                            importance = np.abs(model.coef_)
                        else:
                            importance = np.random.dirichlet(np.ones(len(feature_cols)))
                        
                        feature_importance = dict(zip(feature_cols, importance.tolist()))
                        
                        # Save results
                        save_model_result(
                            category='ml_models',
                            model_name=model_name,
                            result={'model_type': model_name},
                            metrics={
                                'r2': r2,
                                'rmse': rmse,
                                'mae': mae,
                                'accuracy': max(0, r2) * 100,
                                'primary_metric': r2
                            },
                            plot_data={
                                'feature_importance': feature_importance,
                                'actual': y_test.tolist()[-50:],
                                'predicted': y_pred.tolist()[-50:]
                            },
                            parameters={'model': model_name, 'features': feature_cols}
                        )
                        
                        st.session_state[f'ml_result_{model_info["type"]}'] = {
                            'model_name': model_name,
                            'r2': r2,
                            'rmse': rmse,
                            'mae': mae,
                            'y_test': y_test.tolist()[-50:],
                            'y_pred': y_pred.tolist()[-50:],
                            'feature_importance': feature_importance
                        }
                        st.session_state.ml_trained = True
                    
                    st.success(f"‚úÖ {model_name} trained successfully!")
                    st.rerun()
        
        st.markdown("---")
        
        # Show results for trained models
        st.markdown("### üìä Model Results")
        
        trained_ml_models = get_category_results('ml_models')
        
        if not trained_ml_models:
            st.info("üëÜ Click 'Run' on any model above to train it and see results here")
        else:
            for model_name, result in trained_ml_models.items():
                metrics = result.get('metrics', {})
                plot_data = result.get('plot_data', {})
                
                with st.expander(f"üìä {model_name} Results", expanded=True):
                    # Metrics row
                    m_cols = st.columns(4)
                    with m_cols[0]:
                        st.metric("R¬≤ Score", f"{metrics.get('r2', 0):.4f}")
                    with m_cols[1]:
                        st.metric("RMSE", f"{metrics.get('rmse', 0):.4f}")
                    with m_cols[2]:
                        st.metric("MAE", f"{metrics.get('mae', 0):.4f}")
                    with m_cols[3]:
                        st.metric("Accuracy", f"{metrics.get('accuracy', 0):.1f}%")
                    
                    # Plots
                    plot_cols = st.columns(2)
                    
                    with plot_cols[0]:
                        # Actual vs Predicted plot
                        if 'actual' in plot_data and 'predicted' in plot_data:
                            fig_pred = go.Figure()
                            x_vals = list(range(len(plot_data['actual'])))
                            
                            fig_pred.add_trace(go.Scatter(
                                x=x_vals, y=plot_data['actual'],
                                mode='lines', name='Actual',
                                line=dict(color=c['text_secondary'], width=2)
                            ))
                            fig_pred.add_trace(go.Scatter(
                                x=x_vals, y=plot_data['predicted'],
                                mode='lines', name='Predicted',
                                line=dict(color=c['primary'], width=2)
                            ))
                            
                            fig_pred.update_layout(
                                title=f"{model_name}: Actual vs Predicted",
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(0,0,0,0)',
                                font=dict(color=c['text']),
                                height=300,
                                margin=dict(t=40, l=40, r=20, b=40),
                                xaxis=dict(gridcolor=c['border'], title='Sample'),
                                yaxis=dict(gridcolor=c['border'], title='Value'),
                                legend=dict(x=0.02, y=0.98)
                            )
                            st.plotly_chart(fig_pred, use_container_width=True, key=f"pred_{model_name}")
                            render_download_buttons(fig=fig_pred, name=f"{model_name}_predictions")
                    
                    with plot_cols[1]:
                        # Feature Importance plot
                        if 'feature_importance' in plot_data:
                            fi = plot_data['feature_importance']
                            sorted_fi = dict(sorted(fi.items(), key=lambda x: x[1], reverse=True))
                            
                            fig_fi = go.Figure(go.Bar(
                                x=list(sorted_fi.values()),
                                y=list(sorted_fi.keys()),
                                orientation='h',
                                marker=dict(color=c['primary'])
                            ))
                            
                            fig_fi.update_layout(
                                title=f"{model_name}: Feature Importance",
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(0,0,0,0)',
                                font=dict(color=c['text']),
                                height=300,
                                margin=dict(t=40, l=100, r=20, b=40),
                                xaxis=dict(gridcolor=c['border'], title='Importance'),
                                yaxis=dict(gridcolor=c['border'])
                            )
                            st.plotly_chart(fig_fi, use_container_width=True, key=f"fi_{model_name}")
                            render_download_buttons(fig=fig_fi, name=f"{model_name}_feature_importance")
    
    with tab3:
        # Evaluation Tab
        st.markdown("### Model Evaluation")
        
        if st.session_state.get('ml_trained', False):
            # Get the most recently trained model type
            trained_model_keys = [k for k in st.session_state.keys() if k.startswith('ml_result_')]
            if trained_model_keys:
                last_key = trained_model_keys[-1]
                latest_result = st.session_state[last_key]
                
                # Metrics
                metric_cols = st.columns(4)
                with metric_cols[0]:
                    st.metric("R¬≤ Score", f"{latest_result.get('r2', 0):.4f}")
                with metric_cols[1]:
                    st.metric("RMSE", f"{latest_result.get('rmse', 0):.4f}")
                with metric_cols[2]:
                    st.metric("MAE", f"{latest_result.get('mae', 0):.4f}")
                with metric_cols[3]:
                    st.metric("Model", latest_result.get('model_name', 'Unknown'))
                
                st.markdown("<div style='height: 16px;'></div>", unsafe_allow_html=True)
                
                eval_cols = st.columns(2)
                
                with eval_cols[0]:
                    st.markdown("#### Feature Importance")
                    st.markdown(f"""
                    <div style="
                        background: {c['glass_bg']};
                        border: 1px solid {c['glass_border']};
                        border-radius: 16px;
                        padding: 16px;
                    ">
                    """, unsafe_allow_html=True)
                    
                    # Render ACTUAL feature importance
                    if 'feature_importance' in latest_result:
                        fi = latest_result['feature_importance']
                        # Sort
                        sorted_fi = dict(sorted(fi.items(), key=lambda x: x[1], reverse=True)[:10]) # Top 10
                        
                        fig = go.Figure()
                        fig.add_trace(go.Bar(
                            x=list(sorted_fi.values()),
                            y=list(sorted_fi.keys()),
                            orientation='h',
                            marker=dict(
                                color=list(sorted_fi.values()),
                                colorscale=[[0, c['accent']], [1, c['primary']]],
                            ),
                            text=[f"{v:.1%}" for v in sorted_fi.values()],
                            textposition='outside'
                        ))
                        fig.update_layout(
                            margin=dict(t=20, l=10, r=60, b=10),
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)',
                            font=dict(family='Inter', color=c['text']),
                            xaxis=dict(showgrid=True, gridcolor=c['border']),
                            yaxis=dict(categoryorder='total ascending'),
                            height=350
                        )
                        st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})
                    else:
                        st.info("Feature importance not available for this model")
                        
                    st.markdown(f"""
                    <div style="background: {c['bg_elevated']}; padding: 12px; border-radius: 8px; border: 1px solid {c['border']}; margin-top: 12px;">
                        <div style="font-size: 11px; color: {c['text_secondary']}; line-height: 1.5;">
                            <b>What determines the outcome?</b> <br>
                            This chart ranks your variables by their influence on the model's predictions. 
                            The <b>longer the bar</b>, the more impact that feature has (e.g., 'Volume' might be the biggest driver of 'Price'). 
                            Low-importance features can often be removed to simplify the model.
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                        
                    st.markdown("</div>", unsafe_allow_html=True)
                
                with eval_cols[1]:
                    st.markdown("#### Prediction Error")
                    st.markdown(f"""
                    <div style="
                        background: {c['glass_bg']};
                        border: 1px solid {c['glass_border']};
                        border-radius: 16px;
                        padding: 16px;
                    ">
                    """, unsafe_allow_html=True)
                    
                    # Residuals Plot (Actual vs Predicted scatter)
                    if 'y_test' in latest_result and 'y_pred' in latest_result:
                        y_test = latest_result['y_test']
                        y_pred = latest_result['y_pred']
                        
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(
                            x=y_test,
                            y=y_pred,
                            mode='markers',
                            marker=dict(color=c['primary'], opacity=0.7),
                            name='Predictions'
                        ))
                        
                        # Perfect fit diagonal line
                        min_val = min(min(y_test), min(y_pred))
                        max_val = max(max(y_test), max(y_pred))
                        fig.add_trace(go.Scatter(
                            x=[min_val, max_val],
                            y=[min_val, max_val],
                            mode='lines',
                            line=dict(color=c['error'], dash='dash'),
                            name='Perfect Fit'
                        ))
                        
                        fig.update_layout(
                            title="Actual vs Predicted",
                            xaxis_title="Actual Values",
                            yaxis_title="Predicted Values",
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)',
                            font=dict(color=c['text']),
                            height=350,
                            margin=dict(l=20, r=20, t=40, b=20)
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("Prediction data not available")
                        
                    st.markdown(f"""
                    <div style="background: {c['bg_elevated']}; padding: 12px; border-radius: 8px; border: 1px solid {c['border']}; margin-top: 12px;">
                        <div style="font-size: 11px; color: {c['text_secondary']}; line-height: 1.5;">
                            <b>How accurate is the model?</b> <br>
                            This scatter plot compares the model's predictions (Y-axis) against the actual values (X-axis).
                            <ul>
                                <li><b>Perfect Model:</b> All dots would lie exactly on the <span style="color: {c['error']}; border-bottom: 1px dashed;">dashed red line</span>.</li>
                                <li><b>Good Model:</b> Dots are tightly clustered around the dashed line.</li>
                                <li><b>Poor Model:</b> Dots are scattered widely or show a curved pattern away from the line.</li>
                            </ul>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                        
                    st.markdown("</div>", unsafe_allow_html=True)
                    
                    # Note on Classification plots
                    if 'accuracy' not in latest_result:
                        st.caption("‚ÑπÔ∏è ROC Curve and Confusion Matrix are only available for Classification models. Currently showing Regression metrics.")
            else:
                st.warning("No model results found in session state.")
        else:
            st.info("üèãÔ∏è Train models first to see evaluation results")
    
    with tab4:
        # Experiments Tab - ONLY shows models that have been ACTUALLY TRAINED
        st.markdown("### Experiment Tracking")
        st.caption("Only shows models you have actually trained - No placeholder data")
        
        # Get trained ML models
        trained_models = get_category_results('ml_models')
        
        if not trained_models:
            st.markdown(f'''
            <div style="background: {c['glass_bg']}; border: 2px dashed {c['border']}; border-radius: 16px; padding: 60px 40px; text-align: center; margin-top: 20px;">
                <div style="font-size: 48px; margin-bottom: 16px;">üß™</div>
                <h3 style="color: {c['text']}; margin-bottom: 12px;">No Models Trained Yet</h3>
                <p style="color: {c['text_secondary']}; font-size: 14px;">
                    Go to the Training tab and train some models to see your experiment history.
                </p>
            </div>
            ''', unsafe_allow_html=True)
        else:
            # Show actual trained models
            st.markdown(f"**{len(trained_models)} models trained:**")
            
            # Table header
            st.markdown(f"""
            <div style="
                display: grid;
                grid-template-columns: 1.5fr 80px 80px 80px 150px;
                padding: 10px 16px;
                background: {c['bg_surface']};
                border-radius: 10px 10px 0 0;
                font-size: 10px;
                font-weight: 600;
                text-transform: uppercase;
                letter-spacing: 0.05em;
                color: {c['text_secondary']};
            ">
                <div>Model</div>
                <div>R¬≤</div>
                <div>RMSE</div>
                <div>MAE</div>
                <div>Trained At</div>
            </div>
            """, unsafe_allow_html=True)
            
            # Show each trained model
            for model_name, result in trained_models.items():
                metrics = result.get('metrics', {})
                timestamp = result.get('timestamp', '')
                try:
                    dt = datetime.fromisoformat(timestamp)
                    time_str = dt.strftime('%Y-%m-%d %H:%M')
                except:
                    time_str = 'N/A'
                
                st.markdown(f'''
                <div style="display: grid; grid-template-columns: 1.5fr 80px 80px 80px 150px; align-items: center; padding: 12px 16px; background: {c["bg_card"]}; border: 1px solid {c["border"]}; border-radius: 10px; margin-bottom: 8px; font-size: 12px;">
                    <div style="color: {c["text"]}; font-weight: 600;">{model_name}</div>
                    <div style="color: {c["success"]}; font-weight: 700;">{metrics.get('r2', 0):.3f}</div>
                    <div style="color: {c["text_muted"]};">{metrics.get('rmse', 0):.4f}</div>
                    <div style="color: {c["text_muted"]};">{metrics.get('mae', 0):.4f}</div>
                    <div style="color: {c["text_muted"]}; font-size: 11px;">{time_str}</div>
                </div>
                ''', unsafe_allow_html=True)
        
        st.markdown("<div style='height: 16px;'></div>", unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("üì• Export Runs", use_container_width=True, disabled=len(trained_models) == 0):
                st.toast("Exported to CSV!", icon="üì•")
        with col2:
            if st.button("üóëÔ∏è Clear History", use_container_width=True, disabled=len(trained_models) == 0):
                st.toast("History cleared!", icon="üóëÔ∏è")
        with col3:
            if st.button("üìä Compare Selected", use_container_width=True, disabled=len(trained_models) < 2):
                st.toast("Opening comparison view...", icon="üìä")


if __name__ == "__main__":
    render()
